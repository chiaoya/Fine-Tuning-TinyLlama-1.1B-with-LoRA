# Fine-Tuning-TinyLlama-1.1B-with-LoRA
This repository contains a Jupyter Notebook for fine-tuning the TinyLlama-1.1B model using Parameter-Efficient Fine-Tuning (PEFT) techniques, specifically LoRA. The model is trained on the Alpaca dataset to improve its instruction-following capabilities.
